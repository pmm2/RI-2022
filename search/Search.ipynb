{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processamento de Consulta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "limpando o input da consulta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Using cached bs4-0.0.1.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/lib/python3/dist-packages (from bs4) (4.8.2)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1272 sha256=f2a309e8d09339f277cdcba26ae4f7ced33d1f3ddb512deedd77915e461c39dc\n",
      "  Stored in directory: /home/joao/.cache/pip/wheels/75/78/21/68b124549c9bdc94f822c02fb9aa3578a669843f9767776bca\n",
      "Successfully built bs4\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unidecode\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def clear_query_input(query, field=None, usestopwords=False):\n",
    "\n",
    "    # separa as palavras da query\n",
    "    if type(query) == str:\n",
    "        substr = re.findall(r'\"(.*?)\"', query)\n",
    "        words = re.sub(r'\"(.*?)\"', '', query)\n",
    "        words = words.lower().strip().split(' ')\n",
    "        words = words + substr\n",
    "   \n",
    "    # remove simbolos da query\n",
    "    toRemove = r'[.*,;\\(\\)\\'\\\"\\?\\!%\\$]'\n",
    "    for i in range(len(words)):\n",
    "        words[i] = re.sub(toRemove, '', words[i])\n",
    "        words[i] = unidecode.unidecode(words[i])\n",
    "    \n",
    "    # coloca os stop words em caso decidirmos usa-los \n",
    "    if usestopwords:\n",
    "        set_sw = set(stopwords.words('english'))\n",
    "        newWords = []\n",
    "        for word in words:\n",
    "            if not word in set_sw:\n",
    "                if (field):\n",
    "                    newWords.append(word + '.' + field)\n",
    "                else:\n",
    "                    newWords.append(word)\n",
    "        return list(set(newWords))\n",
    "    \n",
    "    # caso ele seja a consulta seja de um campo especifico, ele Ã© atribuido as palavras\n",
    "    if (field):\n",
    "        for i in range(len(words)):\n",
    "            words[i] = words[i] + '.' + field\n",
    "    return list(set(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['consulta', 'uma', 'pequena']\n",
      "['uma.title', 'pequena.title', 'consulta.title']\n"
     ]
    }
   ],
   "source": [
    "exemplo = 'Uma pequena consulta'\n",
    "print(clear_query_input(exemplo))\n",
    "print(clear_query_input(exemplo, field='title'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranqueamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "usando os pesos com tfidf: tf * idf\n",
    "    para o termo-documento = f(i,j) * log(N/ni)\n",
    "    para a termo-consulta = (0.5 * 0.5(f(i,q)/max(i)f(i,q)) * log(N/ni)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import log\n",
    "\n",
    "def get_idf(posting, num_docs):\n",
    "\n",
    "    idf = log(num_docs/len(posting))\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_Score(terms, tfidf, invlist, num_docs, doc_lengths, n):\n",
    "    scores = {i: 0 for i in range(1, num_docs + 1)}\n",
    "    \n",
    "    #term-at-a-time\n",
    "    for term in terms:\n",
    "        w_term_query = term.count(term)\n",
    "        if (tfidf):\n",
    "            w_term_query = 0.5 + 0.5 * \\\n",
    "                (w_term_query /\n",
    "                 max([i for i, val in enumerate(terms) if val == term])+1)\n",
    "            w_term_query *= get_idf(invlist[term], num_docs)\n",
    "        for post in term:\n",
    "            w_doc_term = post[1]  # tf\n",
    "            if tfidf:\n",
    "                w_doc_term *= get_idf(invlist[term], num_docs)\n",
    "            scores[post[0]] += w_term_query * w_doc_term\n",
    "    for d in range(1, num_docs + 1):\n",
    "        scores[d] /= doc_lengths[d]\n",
    "    scores = sorted(scores.items, key=lambda x: x[1], reverse=True)\n",
    "    return scores[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_docs_len(docs_path_map='./data/data_map.json'):\n",
    "    lengths = {}\n",
    "    with open(docs_path_map, 'r') as map:\n",
    "        map_docs = map.read()\n",
    "        map_docs = json.loads(map_docs)\n",
    "    for id in map_docs:\n",
    "        with open(f\"../data/htmls/{map_docs[id]['arquivo']}.html\") as html:\n",
    "            lengths[id] = len(BeautifulSoup(\n",
    "                html.read(), 'html.parser').text.split(' '))\n",
    "    return lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14895\n"
     ]
    }
   ],
   "source": [
    "# pegando tamanho dos arquivos\n",
    "docs_len = get_docs_len(docs_path_map='../data/data_map.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%cmd` not found.\n"
     ]
    }
   ],
   "source": [
    "#\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
